# -*- coding: utf-8 -*-
"""tugas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12WXiyO_I2fVR4oAh6837D-kRFVhOGbyE
"""

# Commented out IPython magic to ensure Python compatibility.
#Phase 1 — Data Exploration
# Tampilkan plot di notebook
# %matplotlib inline
# Impor pandas dengan alias pd
import pandas as pd
# Impor numpy dengan alias np
import numpy as np
# Impor pyplot dari matplotlib dengan alias plt
import matplotlib.pyplot as plt
# Impor seaborn dengan alias sns
import seaborn as sns

# Baca file csv yang bernama diabetes.csv menggunakan pandas dan simpan dalam variabel diabetes
diabetes = pd.read_csv('https://github.com/NaseemMasaid/tugasDatmin/blob/main/diabetes.csv')
# Cetak nama kolom dari dataframe diabetes
print(diabetes.columns)

# Tampilkan lima baris pertama dari dataframe diabetes
diabetes.head()

# Cetak dimensi (jumlah baris dan kolom) dari dataframe diabetes menggunakan metode format
print("Dimensi kumpulan data diabetes : {}".format(diabetes.shape))

# Kelompokkan data berdasarkan kolom Outcome (0 atau 1) dan hitung jumlahnya untuk setiap kelompok
diabetes.groupby('Outcome').size()

# Buat histogram untuk setiap kolom numerik dari dataframe diabetes dengan ukuran gambar 9 x 9
diabetes.hist(figsize=(9, 9))

# Buat histogram untuk setiap kolom numerik dari dataframe diabetes, dibagi berdasarkan kelompok Outcome (0 atau 1), dengan ukuran gambar 9 x 9
diabetes.groupby('Outcome').hist(figsize=(9, 9))

#Phase 2— Data Cleaning
# Cek apakah ada nilai yang hilang (null) di setiap kolom dari dataframe diabetes dan jumlahkan
diabetes.isnull().sum()

#Cek apakah ada nilai yang tidak tersedia (na) di setiap kolom dari dataframe diabetes dan jumlahkan
diabetes.isna().sum()

# Cetak "Total : " dan jumlah baris dari dataframe diabetes yang memiliki nilai BloodPressure sama dengan 0 menggunakan atribut shape
print("Total : ", diabetes[diabetes.BloodPressure == 0].shape[0])
# Cetak jumlah baris dari dataframe diabetes yang memiliki nilai BloodPressure sama dengan 0, dibagi berdasarkan kelompok Outcome (0 atau 1), dan hitung berdasarkan kolom Age menggunakan metode groupby dan count
print(diabetes[diabetes.BloodPressure == 0].groupby('Outcome')['Age'].count())

# Cetak "Total : " dan jumlah baris dari dataframe diabetes yang memiliki nilai Glucose sama dengan 0 menggunakan atribut shape
print("Total : ", diabetes[diabetes.Glucose == 0].shape[0])
# Cetak jumlah baris dari dataframe diabetes yang memiliki nilai Glucose sama dengan 0, dibagi berdasarkan kelompok Outcome (0 atau 1), dan hitung berdasarkan kolom Age menggunakan metode groupby dan count
print(diabetes[diabetes.Glucose == 0].groupby('Outcome')['Age'].count())

# Cetak "Total : " dan jumlah baris dari dataframe diabetes yang memiliki nilai SkinThickness sama dengan 0 menggunakan atribut shape
print("Total : ", diabetes[diabetes.SkinThickness == 0].shape[0])
# Cetak jumlah baris dari dataframe diabetes yang memiliki nilai SkinThickness sama dengan 0, dibagi berdasarkan kelompok Outcome (0 atau 1), dan hitung berdasarkan kolom Age menggunakan metode groupby dan count
print(diabetes[diabetes.SkinThickness == 0].groupby('Outcome')['Age'].count())

# Cetak "Total : " dan jumlah baris dari dataframe diabetes yang memiliki nilai BMI sama dengan 0 menggunakan atribut shape
print("Total : ", diabetes[diabetes.BMI == 0].shape[0])
# Cetak jumlah baris dari dataframe diabetes yang memiliki nilai BMI sama dengan 0, dibagi berdasarkan kelompok Outcome (0 atau 1), dan hitung berdasarkan kolom Age menggunakan metode groupby dan count
print(diabetes[diabetes.BMI == 0].groupby('Outcome')['Age'].count())

# Cetak "Total : " dan jumlah baris dari dataframe diabetes yang memiliki nilai Insulin sama dengan 0 menggunakan atribut shape
print("Total : ", diabetes[diabetes.Insulin == 0].shape[0])
# Cetak jumlah baris dari dataframe diabetes yang memiliki nilai Insulin sama dengan 0, dibagi berdasarkan kelompok Outcome (0 atau 1), dan hitung berdasarkan kolom Age menggunakan metode groupby dan count
print(diabetes[diabetes.Insulin == 0].groupby('Outcome')['Age'].count())

#Phase 3— Feature Engineering
# Buat dataframe baru bernama diabetes_mod yang berisi data dari dataframe diabetes yang tidak memiliki nilai BloodPressure, BMI, atau Glucose sama dengan 0 menggunakan operator logika &
diabetes_mod = diabetes[(diabetes.BloodPressure != 0) & (diabetes.BMI != 0) & (diabetes.Glucose != 0)]
# Cetak dimensi (jumlah baris dan kolom) dari dataframe diabetes_mod menggunakan atribut shape
print(diabetes_mod.shape)

# Buat daftar bernama fitur (variabel independen) yang akan digunakan untuk memprediksi respons (variabel dependen)
feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
# Buat matriks fitur X yang berisi nilai-nilai dari kolom-kolom fitur yang dipilih dari dataframe diabetes_mod
X = diabetes_mod[feature_names]
# Buat vektor respons y yang berisi nilai-nilai dari kolom Outcome (0 atau 1) dari dataframe diabetes_mod
y = diabetes_mod.Outcome

#Phase 4— Model Selection
# Impor kelas KNeighborsClassifier dari modul sklearn.neighbors untuk menggunakan metode klasifikasi berdasarkan tetangga terdekat
from sklearn.neighbors import KNeighborsClassifier
# Impor kelas SVC dari modul sklearn.svm untuk menggunakan metode klasifikasi berdasarkan support vector machine
from sklearn.svm import SVC
# Impor kelas LogisticRegression dari modul sklearn.linear_model untuk menggunakan metode klasifikasi berdasarkan regresi logistik
from sklearn.linear_model import LogisticRegression
# Impor kelas DecisionTreeClassifier dari modul sklearn.tree untuk menggunakan metode klasifikasi berdasarkan pohon keputusan
from sklearn.tree import DecisionTreeClassifier
# Impor kelas GaussianNB dari modul sklearn.naive_bayes untuk menggunakan metode klasifikasi berdasarkan naive bayes dengan asumsi distribusi normal
from sklearn.naive_bayes import GaussianNB
# Impor kelas RandomForestClassifier dari modul sklearn.ensemble untuk menggunakan metode klasifikasi berdasarkan hutan acak, yaitu ensemble dari pohon keputusan yang dibangun secara acak
from sklearn.ensemble import RandomForestClassifier
# Impor kelas GradientBoostingClassifier dari modul sklearn.ensemble untuk menggunakan metode klasifikasi berdasarkan gradient boosting, yaitu ensemble dari pohon keputusan yang dibangun secara bertahap dengan mengurangi kesalahan prediksi sebelumnya
from sklearn.ensemble import GradientBoostingClassifier

# Impor fungsi train_test_split dari modul sklearn.model_selection untuk membagi data menjadi dua subset: data latih dan data uji, dengan proporsi yang dapat ditentukan
from sklearn.model_selection import train_test_split
# Impor fungsi cross_val_score dari modul sklearn.model_selection untuk melakukan validasi silang, yaitu proses evaluasi model dengan menggunakan beberapa subset data latih dan data uji yang berbeda-beda
from sklearn.model_selection import cross_val_score
# Impor kelas StratifiedKFold dari modul sklearn.model_selection untuk melakukan validasi silang dengan metode stratified k-fold, yaitu membagi data menjadi k lipatan yang seimbang dalam hal proporsi kelas respons di setiap lipatan
from sklearn.model_selection import StratifiedKFold
# Impor fungsi accuracy_score dari modul sklearn.metrics untuk menghitung akurasi prediksi model, yaitu persentase kasus yang diprediksi dengan benar oleh model
from sklearn.metrics import accuracy_score

# Initial model selection process
models = []

# Membuat list kosong untuk menampung model-model yang akan dicoba

models.append(('KNN', KNeighborsClassifier()))
# Menambahkan model KNN (K-Nearest Neighbor) ke dalam list models

models.append(('SVC', SVC(gamma='scale')))
# Menambahkan model SVC (Support Vector Classifier) dengan parameter gamma='scale' ke dalam list models

models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=4000)))
# Menambahkan model Logistic Regression dengan parameter solver='lbfgs' dan max_iter=4000 ke dalam list models

models.append(('DT', DecisionTreeClassifier()))
# Menambahkan model Decision Tree ke dalam list models

models.append(('GNB', GaussianNB()))
# Menambahkan model Naive Bayes ke dalam list models

models.append(('RF', RandomForestClassifier(n_estimators=100)))
# Menambahkan model Random Forest dengan 100 estimators ke dalam list models

models.append(('GB', GradientBoostingClassifier()))
# Menambahkan model Gradient Boosting ke dalam list models

# Bagi data menjadi data latih dan data uji dengan proporsi 75:25 secara default menggunakan fungsi train_test_split
# Gunakan parameter stratify untuk memastikan proporsi kelas respons sama di data latih dan data uji
# Gunakan parameter random_state untuk menentukan seed untuk pembangkit bilangan acak yang digunakan untuk membagi data
# Simpan hasil pembagian data dalam empat variabel: X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = diabetes_mod.Outcome, random_state=0)

# Buat dua daftar kosong bernama names dan scores untuk menyimpan nama dan skor akurasi dari setiap model
names = []
scores = []

# Lakukan iterasi untuk setiap pasangan nama dan model dalam daftar models
for name, model in models:
    # Latih model dengan data latih X_train dan y_train menggunakan metode fit
    model.fit(X_train, y_train)
    # Buat prediksi dengan model untuk data uji X_test menggunakan metode predict
    y_pred = model.predict(X_test)
    # Hitung skor akurasi dari prediksi dengan membandingkan dengan nilai sebenarnya y_test menggunakan fungsi accuracy_score
    scores.append(accuracy_score(y_test, y_pred))
    # Tambahkan nama model ke daftar names
    names.append(name)

# Buat dataframe pandas bernama tr_split yang berisi dua kolom: Name dan Score, dengan nilai dari daftar names dan scores
tr_split = pd.DataFrame({'Name': names, 'Score': scores})
# Cetak dataframe tr_split untuk melihat hasil evaluasi model
print(tr_split)

# Buat objek strat_k_fold yang merupakan instance dari kelas StratifiedKFold dengan parameter n_splits=10, shuffle=True, dan random_state=10
# Ini berarti data akan dibagi menjadi 10 lipatan yang seimbang dalam hal proporsi kelas respons di setiap lipatan, dan lipatan akan diacak dengan seed 10
strat_k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=10)


# Buat dua daftar kosong bernama names dan scores untuk menyimpan nama dan skor akurasi rata-rata dari setiap model
names = []
scores = []

# Lakukan iterasi untuk setiap pasangan nama dan model dalam daftar models
for name, model in models:

    # Hitung skor akurasi rata-rata dari model dengan menggunakan fungsi cross_val_score yang menerima parameter model, X, y, cv=strat_k_fold, dan scoring='accuracy'
    # Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
    score = cross_val_score(model, X, y, cv=strat_k_fold, scoring='accuracy').mean()
    # Tambahkan nama model ke daftar names
    names.append(name)
    # Tambahkan skor akurasi rata-rata ke daftar scores
    scores.append(score)

# Buat dataframe pandas bernama kf_cross_val yang berisi dua kolom: Name dan Score, dengan nilai dari daftar names dan scores
kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})
# Cetak dataframe kf_cross_val untuk melihat hasil evaluasi model
print(kf_cross_val)

# Buat objek axis yang merupakan hasil dari fungsi barplot dari pustaka seaborn yang menerima parameter x, y, dan data
# Ini berarti membuat plot batang horizontal yang menampilkan skor akurasi dari setiap model klasifikasi yang tersimpan dalam dataframe kf_cross_val
axis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)
# Atur label sumbu x dan y dari plot dengan menggunakan metode set dari objek axis
axis.set(xlabel='Classifier', ylabel='Accuracy')

# Lakukan iterasi untuk setiap objek patch dalam daftar axis.patches
# Objek patch adalah representasi grafis dari batang plot
for p in axis.patches:
    # Dapatkan tinggi dari objek patch menggunakan metode get_height
    height = p.get_height()
    # Tambahkan teks di atas objek patch yang menampilkan nilai tingginya dengan format empat angka desimal
    # Gunakan metode text dari objek axis yang menerima parameter x, y, s, dan ha
    # Parameter x dan y adalah koordinat teks, yang dihitung berdasarkan posisi dan lebar objek patch
    # Parameter s adalah string teks, yang dibuat dengan menggunakan metode format
    # Parameter ha adalah horizontal alignment, yang disetel menjadi "center" agar teks berada di tengah batang
    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha="center")

# Tampilkan plot dengan menggunakan fungsi show dari pustaka matplotlib.pyplot
plt.show()

#Phase 5 — Feature Engineering (Revisited)
# Impor kelas RFECV dari modul sklearn.feature_selection untuk menggunakan metode seleksi fitur berdasarkan recursive feature elimination with cross-validation
# Ini berarti memilih fitur secara rekursif dengan menghapus fitur yang kurang penting berdasarkan estimasi koefisien atau pentingnya fitur, dan mengevaluasi kinerja model dengan menggunakan validasi silang
from sklearn.feature_selection import RFECV

logreg_model = LogisticRegression(solver='lbfgs', max_iter=4000)
# Membuat model Logistic Regression

rfecv = RFECV(estimator=logreg_model, step=1, cv=strat_k_fold, scoring='accuracy')
# Membuat objek RFECV dengan:
# estimator: model Logistic Regression
# step: jumlah fitur yang akan dieliminasi pada setiap iterasi (1 fitur)
# cv: metode cross-validation yang digunakan
# scoring: metric yang digunakan untuk mengevaluasi model, yaitu accuracy

rfecv.fit(X, y)
# Melakukan fitting RFECV pada data X dan target y

plt.figure()
# Membuat plot

plt.title('Skor CV Regresi Logistik vs Tidak Ada Fitur')
# Memberi judul plot

plt.xlabel("Jumlah fitur yang dipilih")
# Label sumbu x

plt.ylabel("Skor validasi silang (nb klasifikasi yang benar)")
# Label sumbu y

plt.plot(range(1, len(rfecv.cv_results_["mean_test_score"]) + 1),
rfecv.cv_results_["mean_test_score"])
# Plot nilai accuracy pada setiap iterasi pemilihan fitur

plt.show()
# Menampilkan plot

# Buat daftar bernama feature_importance yang berisi pasangan nama fitur dan nilai boolean yang menunjukkan apakah fitur tersebut dipilih atau tidak oleh objek rfecv
# Objek rfecv adalah instance dari kelas RFECV yang telah dilatih sebelumnya dengan data X dan y
# Gunakan fungsi zip untuk menggabungkan dua daftar: feature_names dan rfecv.support_
# Fungsi zip mengembalikan objek iterator yang dapat dikonversi menjadi daftar dengan fungsi list
feature_importance = list(zip(feature_names, rfecv.support_))

# Buat daftar kosong bernama new_features untuk menyimpan nama fitur yang dipilih oleh objek rfecv
new_features = []

# Lakukan iterasi untuk setiap pasangan key dan value dalam daftar feature_importance
# Gunakan fungsi enumerate untuk mendapatkan indeks (key) dan elemen (value) dari daftar
for key,value in enumerate(feature_importance):
    # Cek apakah nilai boolean dari value[1] adalah True, yang berarti fitur tersebut dipilih oleh objek rfecv
    if(value[1]) == True:
        # Tambahkan nama fitur yang tersimpan dalam value[0] ke daftar new_features
        new_features.append(value[0])

# Cetak daftar new_features untuk melihat nama fitur yang dipilih oleh objek rfecv
print(new_features)

# Hitung skor akurasi
# Buat matriks fitur baru X_new yang berisi nilai-nilai dari kolom-kolom fitur yang dipilih oleh objek rfecv dari dataframe diabetes_mod
X_new = diabetes_mod[new_features]

# Hitung skor akurasi rata-rata dari model logreg_model dengan menggunakan fungsi cross_val_score yang menerima parameter model, X, y, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
# Simpan hasilnya dalam variabel initial_score
initial_score = cross_val_score(logreg_model, X, y, cv=strat_k_fold, scoring='accuracy').mean()
# Cetak "Akurasi awal : " dan nilai initial_score dengan menggunakan metode format
print("Akurasi awal : {} ".format(initial_score))

# Hitung skor akurasi rata-rata dari model logreg_model dengan menggunakan fungsi cross_val_score yang menerima parameter model, X_new, y, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
# Simpan hasilnya dalam variabel fe_score
fe_score = cross_val_score(logreg_model, X_new, y, cv=strat_k_fold, scoring='accuracy').mean()
# Cetak "Accuracy after Feature Selection : " dan nilai fe_score dengan menggunakan metode format
print("Akurasi setelah Pemilihan Fitur : {} ".format(fe_score))

# Buat objek gb_model yang merupakan instance dari kelas GradientBoostingClassifier dengan parameter default
# Ini berarti membuat model klasifikasi berdasarkan gradient boosting, yaitu ensemble dari pohon keputusan yang dibangun secara bertahap dengan mengurangi kesalahan prediksi sebelumnya
gb_model = GradientBoostingClassifier()

# Buat objek gb_rfecv yang merupakan instance dari kelas RFECV dengan parameter estimator=gb_model, step=1, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti melakukan seleksi fitur secara rekursif dengan menghapus satu fitur setiap langkah, dan menggunakan model gb_model sebagai estimator
# Selain itu, menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya sebagai metode evaluasi, dan menggunakan akurasi sebagai metrik skor
gb_rfecv = RFECV(estimator=gb_model, step=1, cv=strat_k_fold, scoring='accuracy')
# Latih objek gb_rfecv dengan data X dan y menggunakan metode fit
# Ini berarti objek gb_rfecv akan memilih fitur terbaik dari data X dan y dengan menggunakan model gb_model dan validasi silang stratified k-fold
gb_rfecv.fit(X, y)

# Buat gambar baru dengan menggunakan fungsi figure dari pustaka matplotlib.pyplot
plt.figure()
# Atur judul gambar menjadi 'Skor Gradient Boost CV vs Jumlah Fitur' dengan menggunakan fungsi title dari pustaka matplotlib.pyplot
plt.title('Skor Gradient Boost CV vs Jumlah Fitur')
# Atur label sumbu x menjadi 'Jumlah fitur yang dipilih' dengan menggunakan fungsi xlabel dari pustaka matplotlib.pyplot
plt.xlabel("Jumlah fitur yang dipilih")
# Atur label sumbu y menjadi 'Cross validation score (nb of correct classifications)' dengan menggunakan fungsi ylabel dari pustaka matplotlib.pyplot
plt.ylabel("Skor validasi silang (nb klasifikasi yang benar)")
# Buat plot garis yang menampilkan skor validasi silang rata-rata dari objek gb_rfecv terhadap jumlah fitur yang dipilih dengan menggunakan fungsi plot dari pustaka matplotlib.pyplot
# Gunakan fungsi range untuk membuat daftar bilangan bulat dari 1 hingga jumlah skor validasi silang rata-rata yang tersimpan dalam atribut cv_results_["mean_test_score"] dari objek rfecv
# Gunakan atribut cv_results_["mean_test_score"] dari objek rfecv untuk mendapatkan nilai skor validasi silang rata-rata untuk setiap jumlah fitur yang dipilih
plt.plot(range(1, len(rfecv.cv_results_["mean_test_score"]) + 1),
rfecv.cv_results_["mean_test_score"])
# Tampilkan gambar dengan menggunakan fungsi show dari pustaka matplotlib.pyplot
plt.show()

# Buat daftar bernama feature_importance yang berisi pasangan nama fitur dan nilai boolean yang menunjukkan apakah fitur tersebut dipilih atau tidak oleh objek gb_rfecv
# Objek gb_rfecv adalah instance dari kelas RFECV yang telah dilatih sebelumnya dengan data X dan y menggunakan model gb_model
# Gunakan fungsi zip untuk menggabungkan dua daftar: feature_names dan gb_rfecv.support_
# Fungsi zip mengembalikan objek iterator yang dapat dikonversi menjadi daftar dengan fungsi list
feature_importance = list(zip(feature_names, gb_rfecv.support_))

# Buat daftar kosong bernama new_features untuk menyimpan nama fitur yang dipilih oleh objek gb_rfecv
new_features = []

# Lakukan iterasi untuk setiap pasangan key dan value dalam daftar feature_importance
# Gunakan fungsi enumerate untuk mendapatkan indeks (key) dan elemen (value) dari daftar
for key,value in enumerate(feature_importance):
    # Cek apakah nilai boolean dari value[1] adalah True, yang berarti fitur tersebut dipilih oleh objek gb_rfecv
    if(value[1]) == True:
        # Tambahkan nama fitur yang tersimpan dalam value[0] ke daftar new_features
        new_features.append(value[0])

# Cetak daftar new_features untuk melihat nama fitur yang dipilih oleh objek gb_rfecv
print(new_features)

# Buat matriks fitur baru X_new_gb yang berisi nilai-nilai dari kolom-kolom fitur yang dipilih oleh objek gb_rfecv dari dataframe diabetes_mod
X_new_gb = diabetes_mod[new_features]

# Hitung skor akurasi rata-rata dari model gb_model dengan menggunakan fungsi cross_val_score yang menerima parameter model, X, y, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
# Simpan hasilnya dalam variabel initial_score
initial_score = cross_val_score(gb_model, X, y, cv=strat_k_fold, scoring='accuracy').mean()
# Cetak "Initial accuracy : " dan nilai initial_score dengan menggunakan metode format
print("Akurasi awal : {} ".format(initial_score))

# Hitung skor akurasi rata-rata dari model gb_model dengan menggunakan fungsi cross_val_score yang menerima parameter model, X_new_gb, y, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
# Simpan hasilnya dalam variabel fe_score
fe_score = cross_val_score(gb_model, X_new_gb, y, cv=strat_k_fold, scoring='accuracy').mean()
# Cetak "Accuracy after Feature Selection : " dan nilai fe_score dengan menggunakan metode format
print("Akurasi setelah Pemilihan Fitur : {} ".format(fe_score))

#Phase 6 — Model Parameter Tuning
# Impor kelas GridSearchCV dari modul sklearn.model_selection untuk menggunakan metode pencarian grid
# Ini sudah dilakukan sebelumnya, tetapi tidak ada salahnya mengulanginya di sini untuk memastikan kelas tersebut tersedia
from sklearn.model_selection import GridSearchCV

# Tentukan parameter
# Buat daftar bernama c_values yang berisi bilangan bulat dari 1 hingga 9 dengan menggunakan fungsi arange dari pustaka numpy
# Fungsi arange mengembalikan objek array yang dapat dikonversi menjadi daftar dengan fungsi list
c_values = list(np.arange(1, 10))

# Buat daftar bernama param_grid yang berisi dua kamus yang menentukan kombinasi parameter yang akan dicoba untuk model regresi logistik
# Parameter C adalah parameter inversi regularisasi, yang menentukan seberapa kuat model menghindari overfitting
# Parameter penalty adalah parameter jenis regularisasi, yang menentukan apakah model menggunakan norma L1 atau L2 untuk mengurangi kompleksitas model
# Parameter solver adalah parameter algoritma optimisasi, yang menentukan metode yang digunakan untuk menemukan solusi terbaik untuk model
# Parameter multi_class adalah parameter strategi klasifikasi, yang menentukan apakah model menggunakan one-vs-rest (ovr) atau multinomial untuk klasifikasi multikelas
param_grid = [
    {'C': c_values, 'penalty': ['l1'], 'solver' : ['liblinear'], 'multi_class' : ['ovr']},
    {'C': c_values, 'penalty': ['l2'], 'solver' : ['liblinear', 'newton-cg', 'lbfgs'], 'multi_class' : ['ovr']}
]

# Buat objek grid yang merupakan instance dari kelas GridSearchCV dengan parameter estimator=LogisticRegression(), param_grid=param_grid, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti melakukan pencarian grid, yaitu proses optimisasi parameter model dengan mencoba semua kombinasi parameter yang ditentukan dalam daftar param_grid
# Selain itu, menggunakan model regresi logistik sebagai estimator, validasi silang stratified k-fold yang telah ditentukan sebelumnya sebagai metode evaluasi, dan akurasi sebagai metrik skor
grid = GridSearchCV(LogisticRegression(), param_grid, cv=strat_k_fold, scoring='accuracy')
# Latih objek grid dengan data X_new dan y menggunakan metode fit
# Ini berarti objek grid akan menemukan parameter terbaik untuk model regresi logistik dengan menggunakan data X_new dan y dan pencarian grid
grid.fit(X_new, y)

# Cetak parameter terbaik yang ditemukan oleh objek grid dengan menggunakan atribut best_params_
# Ini akan menampilkan kamus yang berisi nama dan nilai parameter terbaik untuk model regresi logistik
print(grid.best_params_)
# Cetak estimator terbaik yang ditemukan oleh objek grid dengan menggunakan atribut best_estimator_
# Ini akan menampilkan objek regresi logistik yang telah dilatih dengan parameter terbaik dan data X_new dan y
print(grid.best_estimator_)

# Buat objek logreg_new yang merupakan instance dari kelas LogisticRegression dengan parameter sesuai dengan parameter terbaik yang ditemukan oleh objek grid
# Ini berarti membuat model regresi logistik baru dengan parameter C=1, multi_class='ovr', penalty='l2', dan solver='liblinear'
logreg_new = LogisticRegression(C=1, multi_class='ovr', penalty='l2', solver='liblinear')

# Hitung skor akurasi rata-rata dari model logreg_new dengan menggunakan fungsi cross_val_score yang menerima parameter model, X_new, y, cv=strat_k_fold, dan scoring='accuracy'
# Ini berarti model akan dilatih dan dievaluasi dengan menggunakan validasi silang stratified k-fold yang telah ditentukan sebelumnya
# Simpan hasilnya dalam variabel initial_score
initial_score = cross_val_score(logreg_new, X_new, y, cv=strat_k_fold, scoring='accuracy').mean()
# Cetak "Akurasi akhir : " dan nilai initial_score dengan menggunakan metode format
print("Akurasi akhir : {} ".format(initial_score))
